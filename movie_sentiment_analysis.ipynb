{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Text Translation and Sentiment Analysis using Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Project Overview:\n",
    "\n",
    "The objective of this project is to analyze the sentiment of movie reviews in three different languages - English, French, and Spanish. We have been given 30 movies, 10 in each language, along with their reviews and synopses in separate CSV files named `movie_reviews_eng.csv`, `movie_reviews_fr.csv`, and `movie_reviews_sp.csv`.\n",
    "\n",
    "- The first step of this project is to convert the French and Spanish reviews and synopses into English. This will allow us to analyze the sentiment of all reviews in the same language. We will be using pre-trained transformers from HuggingFace to achieve this task.\n",
    "\n",
    "- Once the translations are complete, we will create a single dataframe that contains all the movies along with their reviews, synopses, and year of release in all three languages. This dataframe will be used to perform sentiment analysis on the reviews of each movie.\n",
    "\n",
    "- Finally, we will use pretrained transformers from HuggingFace to analyze the sentiment of each review. The sentiment analysis results will be added to the dataframe. The final dataframe will have 30 rows\n",
    "\n",
    "\n",
    "The output of the project will be a CSV file with a header row that includes column names such as **Title**, **Year**, **Synopsis**, **Review**, **Review Sentiment**, and **Original Language**. The **Original Language** column will indicate the language of the review and synopsis (*en/fr/sp*) before translation. The dataframe will consist of 30 rows, with each row corresponding to a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:35:36.669812Z",
     "start_time": "2024-10-28T08:35:36.665487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml/bin/python\n",
      "['/Users/chaklader/Documents/Education/Udacity/Deep_Learning/Projects/3_movie_sentiment_analysis', '/usr/local/Cellar/apache-spark/3.1.2/libexec/python', '/Users/chaklader/Documents/Education/Udacity/Deep_Learning/Projects/3_movie_sentiment_analysis/$', '/opt/miniconda3/envs/ml/lib/python312.zip', '/opt/miniconda3/envs/ml/lib/python3.12', '/opt/miniconda3/envs/ml/lib/python3.12/lib-dynload', '', '/opt/miniconda3/envs/ml/lib/python3.12/site-packages', '/opt/miniconda3/envs/ml/lib/python3.12/site-packages/setuptools/_vendor']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:35:39.509736Z",
     "start_time": "2024-10-28T08:35:37.536749Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.56.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "print(f\"Transformers version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Get data from `.csv` files and then preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:39:33.626566Z",
     "start_time": "2024-10-28T08:39:33.621008Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Reads movie data from CSV files in three languages (English, French, Spanish) and \n",
    "        combines them into a single DataFrame with language identification for multilingual \n",
    "        sentiment analysis processing.\n",
    "    \n",
    "    Parameters:\n",
    "        None - Function reads from predefined CSV file paths in the data/ directory\n",
    "    \n",
    "    Process Flow:\n",
    "        1. Define consistent column names for all CSV files\n",
    "        2. Read English, French, and Spanish movie review CSV files\n",
    "        3. Add 'Original Language' column to each DataFrame (en/fr/sp)\n",
    "        4. Concatenate all DataFrames with reset index\n",
    "        5. Return combined DataFrame ready for translation and analysis\n",
    "    \n",
    "    Outputs:\n",
    "        pd.DataFrame: Combined dataset with columns ['Title', 'Year', 'Synopsis', 'Review', 'Original Language']\n",
    "                     Contains 30 rows (10 movies per language) for sentiment analysis pipeline\n",
    "    \n",
    "    Example:\n",
    "        >>> df = preprocess_data()\n",
    "        >>> print(df.shape)\n",
    "        (30, 5)\n",
    "        >>> print(df['Original Language'].value_counts())\n",
    "        en    10\n",
    "        fr    10\n",
    "        sp    10\n",
    "    \"\"\"\n",
    "    # Read CSV files with consistent column names\n",
    "    column_names = ['Title', 'Year', 'Synopsis', 'Review']\n",
    "    \n",
    "    df_eng = pd.read_csv(\"data/movie_reviews_en.csv\", names=column_names, header=0)\n",
    "    df_fr = pd.read_csv(\"data/movie_reviews_fr.csv\", names=column_names, header=0)\n",
    "    df_sp = pd.read_csv(\"data/movie_reviews_sp.csv\", names=column_names, header=0)\n",
    "    \n",
    "    df_eng['Original Language'] = 'en'\n",
    "    df_fr['Original Language'] = 'fr'\n",
    "    df_sp['Original Language'] = 'sp'\n",
    "    \n",
    "    df_combined = pd.concat([df_eng, df_fr, df_sp], ignore_index=True)\n",
    "    \n",
    "    return df_combined\n",
    "\n",
    "df = preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:40:01.967369Z",
     "start_time": "2024-10-28T08:40:01.959591Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Review</th>\n",
       "      <th>Original Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Les Visiteurs en Amérique</td>\n",
       "      <td>2000</td>\n",
       "      <td>Dans cette suite de la comédie française Les V...</td>\n",
       "      <td>\"Le film est une perte de temps totale. Les bl...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Amélie</td>\n",
       "      <td>2001</td>\n",
       "      <td>Cette comédie romantique raconte l'histoire d'...</td>\n",
       "      <td>\"Amélie est un film absolument charmant qui vo...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Águila Roja</td>\n",
       "      <td>(2009-2016)</td>\n",
       "      <td>Esta serie de televisión española sigue las av...</td>\n",
       "      <td>\"Águila Roja es una serie aburrida y poco inte...</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>El Incidente</td>\n",
       "      <td>2014</td>\n",
       "      <td>En esta película de terror mexicana, un grupo ...</td>\n",
       "      <td>\"El Incidente es una película aburrida y sin s...</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>1994</td>\n",
       "      <td>Forrest Gump (Tom Hanks) is a simple man with ...</td>\n",
       "      <td>\"Forrest Gump is a heartwarming and inspiratio...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Solo: A Star Wars Story</td>\n",
       "      <td>2018</td>\n",
       "      <td>A young Han Solo (Alden Ehrenreich) joins a gr...</td>\n",
       "      <td>\"Dull and pointless, with none of the magic of...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Le Dîner de Cons</td>\n",
       "      <td>1998</td>\n",
       "      <td>Le film suit l'histoire d'un groupe d'amis ric...</td>\n",
       "      <td>\"Je n'ai pas aimé ce film du tout. Le concept ...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Island</td>\n",
       "      <td>2005</td>\n",
       "      <td>In a future where people are cloned for organ ...</td>\n",
       "      <td>\"The Island is a bland and forgettable sci-fi ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>La Casa de Papel</td>\n",
       "      <td>(2017-2021)</td>\n",
       "      <td>Esta serie de televisión española sigue a un g...</td>\n",
       "      <td>\"La Casa de Papel es una serie emocionante y a...</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Intouchables</td>\n",
       "      <td>2011</td>\n",
       "      <td>Ce film raconte l'histoire de l'amitié improba...</td>\n",
       "      <td>\"Intouchables est un film incroyablement touch...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Title         Year  \\\n",
       "18  Les Visiteurs en Amérique         2000   \n",
       "12                     Amélie         2001   \n",
       "25               Águila Roja   (2009-2016)   \n",
       "29               El Incidente         2014   \n",
       "2                Forrest Gump         1994   \n",
       "8     Solo: A Star Wars Story         2018   \n",
       "15           Le Dîner de Cons         1998   \n",
       "9                  The Island         2005   \n",
       "21           La Casa de Papel  (2017-2021)   \n",
       "11               Intouchables         2011   \n",
       "\n",
       "                                             Synopsis  \\\n",
       "18  Dans cette suite de la comédie française Les V...   \n",
       "12  Cette comédie romantique raconte l'histoire d'...   \n",
       "25  Esta serie de televisión española sigue las av...   \n",
       "29  En esta película de terror mexicana, un grupo ...   \n",
       "2   Forrest Gump (Tom Hanks) is a simple man with ...   \n",
       "8   A young Han Solo (Alden Ehrenreich) joins a gr...   \n",
       "15  Le film suit l'histoire d'un groupe d'amis ric...   \n",
       "9   In a future where people are cloned for organ ...   \n",
       "21  Esta serie de televisión española sigue a un g...   \n",
       "11  Ce film raconte l'histoire de l'amitié improba...   \n",
       "\n",
       "                                               Review Original Language  \n",
       "18  \"Le film est une perte de temps totale. Les bl...                fr  \n",
       "12  \"Amélie est un film absolument charmant qui vo...                fr  \n",
       "25  \"Águila Roja es una serie aburrida y poco inte...                sp  \n",
       "29  \"El Incidente es una película aburrida y sin s...                sp  \n",
       "2   \"Forrest Gump is a heartwarming and inspiratio...                en  \n",
       "8   \"Dull and pointless, with none of the magic of...                en  \n",
       "15  \"Je n'ai pas aimé ce film du tout. Le concept ...                fr  \n",
       "9   \"The Island is a bland and forgettable sci-fi ...                en  \n",
       "21  \"La Casa de Papel es una serie emocionante y a...                sp  \n",
       "11  \"Intouchables est un film incroyablement touch...                fr  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Text translation\n",
    "\n",
    "Translate the **Review** and **Synopsis** column values to English.\n",
    "\n",
    "First, we import the `MarianMTModel` and `MarianTokenizer` classes from the `transformers` module, which is a popular Python library for working with transformer-based models such as BERT, GPT, and MarianMT.\n",
    "\n",
    "Next, we set the `model_name` variable to `Helsinki-NLP/opus-mt-en-es`, which is the name of the pre-trained model that will be used for English-to-Spanish translation.  Read more about this pre-trained model [here](https://huggingface.co/Helsinki-NLP/opus-mt-en-es).\n",
    "\n",
    "The `MarianTokenizer` class is then used to instantiate a `tokenizer` object, which will be used to tokenize the input text before passing it to the model.\n",
    "\n",
    "Similarly, the `MarianMTModel` class is used to instantiate a translation `model` object. The model object is initialized with the pre-trained weights of the English-to-Spanish translation model specified by `model_name`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose:\n",
    "    Initializes pre-trained Marian neural machine translation models and tokenizers\n",
    "    for French-to-English and Spanish-to-English translation. Sets up the translation\n",
    "    pipeline components needed for multilingual movie review processing.\n",
    "\n",
    "Parameters:\n",
    "    None - Uses predefined model names from Helsinki-NLP repository\n",
    "\n",
    "Process Flow:\n",
    "    1. Define model names for French-English and Spanish-English translation\n",
    "    2. Load pre-trained MarianMTModel instances from HuggingFace Hub\n",
    "    3. Load corresponding MarianTokenizer instances for text preprocessing\n",
    "    4. Store models and tokenizers in variables for translation pipeline use\n",
    "\n",
    "Outputs:\n",
    "    fr_en_model: MarianMTModel for French to English translation\n",
    "    es_en_model: MarianMTModel for Spanish to English translation  \n",
    "    fr_en_tokenizer: MarianTokenizer for French text preprocessing\n",
    "    es_en_tokenizer: MarianTokenizer for Spanish text preprocessing\n",
    "\n",
    "Example:\n",
    "    >>> print(fr_en_model_name)\n",
    "    \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "    >>> french_text = \"Bonjour le monde\"\n",
    "    >>> inputs = fr_en_tokenizer(french_text, return_tensors=\"pt\")\n",
    "    >>> outputs = fr_en_model.generate(**inputs)\n",
    "\"\"\"\n",
    "\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "fr_en_model_name = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "es_en_model_name = \"Helsinki-NLP/opus-mt-es-en\"\n",
    "\n",
    "fr_en_model = MarianMTModel.from_pretrained(fr_en_model_name)\n",
    "es_en_model = MarianMTModel.from_pretrained(es_en_model_name)\n",
    "\n",
    "fr_en_tokenizer = MarianTokenizer.from_pretrained(fr_en_model_name)\n",
    "es_en_tokenizer = MarianTokenizer.from_pretrained(es_en_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:40:42.888165Z",
     "start_time": "2024-10-28T08:40:18.135928Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/ml/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "def translate(text: str, model, tokenizer) -> str:\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        Translates text from source language to English using pre-trained Marian MT models\n",
    "        from HuggingFace. Handles text preprocessing and tokenization for neural machine\n",
    "        translation with proper truncation and padding.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): Single text string to translate (review or synopsis content)\n",
    "        model: Pre-trained MarianMTModel for translation (e.g., Helsinki-NLP/opus-mt-fr-en)\n",
    "        tokenizer: Corresponding MarianTokenizer for text preprocessing and decoding\n",
    "    \n",
    "    Process Flow:\n",
    "        1. Validate and convert input text to string format\n",
    "        2. Tokenize text with padding, truncation (max 512 tokens) and PyTorch tensors\n",
    "        3. Generate translation using the model's generate() method\n",
    "        4. Decode output tokens to readable text, skipping special tokens\n",
    "        5. Return clean translated text string\n",
    "    \n",
    "    Outputs:\n",
    "        str: Translated text in English, cleaned of special tokens and formatting\n",
    "             Ready for sentiment analysis processing\n",
    "    \n",
    "    Example:\n",
    "        >>> fr_text = \"Ce film est magnifique et très émouvant\"\n",
    "        >>> translated = translate(fr_text, fr_en_model, fr_en_tokenizer)\n",
    "        >>> print(translated)\n",
    "        \"This film is beautiful and very moving\"\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Tokenizes input text and converts it to PyTorch tensors for model processing.\n",
    "\n",
    "    Parameters breakdown:\n",
    "        text: The input string to be tokenized and encoded\n",
    "        return_tensors=\"pt\": Specifies output format as PyTorch tensors (alternative: \"tf\" for TensorFlow, \"np\" for NumPy)\n",
    "                            Required because neural models expect tensor inputs, not raw text\n",
    "        padding=True: Automatically pads shorter sequences to match batch dimensions\n",
    "                    Ensures consistent input shape when processing multiple texts\n",
    "        truncation=True: Cuts off text exceeding max_length to prevent memory overflow\n",
    "                        Essential for handling variable-length inputs safely\n",
    "        max_length=512: Maximum sequence length in tokens (common limit for transformer models)\n",
    "                        Balances memory usage with context preservation\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains 'input_ids' (token indices) and 'attention_mask' (padding indicators)\n",
    "            Ready for direct input to the translation model\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    \"\"\"\n",
    "    Generates translated text using the pre-trained translation model.\n",
    "\n",
    "    Parameter breakdown:\n",
    "        **inputs: Unpacks the dictionary returned by tokenizer into keyword arguments\n",
    "                Equivalent to: model.generate(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "                The ** operator spreads dictionary keys as parameter names automatically\n",
    "        \n",
    "    Process:\n",
    "        Uses the model's generate() method which performs beam search or sampling\n",
    "        to produce the most likely translation sequence token by token\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Raw output token IDs representing the translated text\n",
    "                    Shape: [batch_size, sequence_length] containing integer token indices\n",
    "    \"\"\"\n",
    "    outputs = model.generate(**inputs)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Converts generated token IDs back to human-readable text string.\n",
    "\n",
    "    Parameter breakdown:\n",
    "        outputs[0]: Selects first (and only) sequence from the batch dimension\n",
    "                    Since we're translating one text, we take index 0 from the batch\n",
    "        skip_special_tokens=True: Removes model-specific tokens like <pad>, <eos>, <bos>\n",
    "                                Produces clean output without internal formatting markers\n",
    "\n",
    "    Process:\n",
    "        Maps integer token IDs back to their corresponding text representations\n",
    "        using the tokenizer's vocabulary and decoding rules\n",
    "        \n",
    "    Returns:\n",
    "        str: Clean, readable translated text ready for downstream processing\n",
    "            Free of special tokens and model artifacts\n",
    "    \"\"\"    \n",
    "    translated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:41:24.354453Z",
     "start_time": "2024-10-28T08:40:47.137840Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates boolean masks to identify rows containing French and Spanish content for selective translation.\n",
    "\n",
    "Process:\n",
    "   - Generates boolean Series where True indicates rows matching specific languages\n",
    "   - Uses vectorized comparison operations for efficient DataFrame filtering\n",
    "   - Enables targeted application of language-specific translation models\n",
    "   \n",
    "Returns:\n",
    "   Two pandas.Series objects containing boolean values for row selection\n",
    "\"\"\"\n",
    "fr_mask = df['Original Language'] == 'fr'\n",
    "sp_mask = df['Original Language'] == 'sp'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Configuration dictionary mapping language codes to their translation components.\n",
    "\n",
    "Structure:\n",
    "   - Keys: Language identifiers ('fr', 'sp')\n",
    "   - Values: Tuples containing (boolean_mask, model, tokenizer)\n",
    "   - Centralizes translation settings to eliminate code duplication\n",
    "   - Facilitates easy addition of new language pairs\n",
    "   \n",
    "Returns:\n",
    "   Dictionary with language-specific translation configurations\n",
    "\"\"\"\n",
    "translation_configs = {\n",
    "   'fr': (fr_mask, fr_en_model, fr_en_tokenizer),\n",
    "   'sp': (sp_mask, es_en_model, es_en_tokenizer)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "Let me break this down step-by-step with concrete examples to make it clearer:\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Detailed breakdown of the batch translation loop with step-by-step explanations.\n",
    "\n",
    "What happens in each iteration:\n",
    "1. Python takes one language from translation_configs dictionary\n",
    "2. Unpacks the tuple to get mask, model, and tokenizer for that language\n",
    "3. For each text column ('Review', 'Synopsis'):\n",
    "   - Finds rows where the language matches (using the mask)\n",
    "   - Takes the text from those specific rows and columns\n",
    "   - Applies the translate function to each piece of text\n",
    "   - Puts the translated text back in the same location\n",
    "\n",
    "Example walkthrough:\n",
    "- First iteration: lang='fr', mask=fr_mask, model=fr_en_model, tokenizer=fr_en_tokenizer\n",
    "- Second iteration: lang='sp', mask=sp_mask, model=es_en_model, tokenizer=es_en_tokenizer\n",
    "\"\"\"\n",
    "for lang, (mask, model, tokenizer) in translation_configs.items():\n",
    "    # At this point:\n",
    "    # lang = 'fr' (first time) or 'sp' (second time)\n",
    "    # mask = boolean array showing which rows are this language\n",
    "    # model = the specific translation model for this language\n",
    "    # tokenizer = the specific tokenizer for this language\n",
    "    \n",
    "    for col in ['Review', 'Synopsis']:\n",
    "        # col = 'Review' (first time) or 'Synopsis' (second time)\n",
    "        \n",
    "        # This line does several things:\n",
    "        # 1. df.loc[mask, col] - finds ONLY the rows where mask is True AND the specific column\n",
    "        # 2. .apply() - runs a function on each cell in that selection\n",
    "        # 3. lambda x: translate(x, model, tokenizer) - the function that translates each text\n",
    "        # 4. df.loc[mask, col] = - puts the translated text back in the same spots\n",
    "        \n",
    "        df.loc[mask, col] = df.loc[mask, col].apply(\n",
    "            lambda x: translate(x, model, tokenizer)\n",
    "        )\n",
    "```\n",
    "\n",
    "**Concrete example:**\n",
    "If your DataFrame looks like this:\n",
    "```\n",
    "Row 0: Original Language='en', Review='Great movie', Synopsis='Action film'\n",
    "Row 1: Original Language='fr', Review='Très bon film', Synopsis='Film d'action'  \n",
    "Row 2: Original Language='sp', Review='Película genial', Synopsis='Película de acción'\n",
    "```\n",
    "\n",
    "**First iteration (French):**\n",
    "- `lang = 'fr'`\n",
    "- `mask = [False, True, False]` (only row 1 is French)\n",
    "- Only processes row 1, columns 'Review' and 'Synopsis'\n",
    "- Translates 'Très bon film' → 'Very good film'\n",
    "- Translates 'Film d'action' → 'Action film'\n",
    "\n",
    "**Second iteration (Spanish):**\n",
    "- `lang = 'sp'`  \n",
    "- `mask = [False, False, True]` (only row 2 is Spanish)\n",
    "- Only processes row 2, columns 'Review' and 'Synopsis'\n",
    "- Translates 'Película genial' → 'Great movie'\n",
    "- Translates 'Película de acción' → 'Action movie'\n",
    "\n",
    "The key insight is that `df.loc[mask, col]` only selects the specific cells that need translation, not the entire DataFrame.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Detailed breakdown of the batch translation loop with step-by-step explanations.\n",
    "\n",
    "What happens in each iteration:\n",
    "1. Python takes one language from translation_configs dictionary\n",
    "2. Unpacks the tuple to get mask, model, and tokenizer for that language\n",
    "3. For each text column ('Review', 'Synopsis'):\n",
    "   - Finds rows where the language matches (using the mask)\n",
    "   - Takes the text from those specific rows and columns\n",
    "   - Applies the translate function to each piece of text\n",
    "   - Puts the translated text back in the same location\n",
    "\n",
    "Example walkthrough:\n",
    "\n",
    "- First iteration: lang='fr', mask=fr_mask, model=fr_en_model, tokenizer=fr_en_tokenizer\n",
    "- Second iteration: lang='sp', mask=sp_mask, model=es_en_model, tokenizer=es_en_tokenizer\n",
    "\"\"\"\n",
    "\n",
    "for lang, (mask, model, tokenizer) in translation_configs.items():\n",
    "    # At this point:\n",
    "    # lang = 'fr' (first time) or 'sp' (second time)\n",
    "    # mask = boolean array showing which rows are this language\n",
    "    # model = the specific translation model for this language\n",
    "    # tokenizer = the specific tokenizer for this language\n",
    "    \n",
    "    for col in ['Review', 'Synopsis']:\n",
    "        # col = 'Review' (first time) or 'Synopsis' (second time)\n",
    "        \n",
    "        # This line does several things:\n",
    "        # 1. df.loc[mask, col] - finds ONLY the rows where mask is True AND the specific column\n",
    "        # 2. .apply() - runs a function on each cell in that selection\n",
    "        # 3. lambda x: translate(x, model, tokenizer) - the function that translates each text\n",
    "        # 4. df.loc[mask, col] = - puts the translated text back in the same spots\n",
    "        \n",
    "        df.loc[mask, col] = df.loc[mask, col].apply(\n",
    "            lambda x: translate(x, model, tokenizer)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:41:48.961210Z",
     "start_time": "2024-10-28T08:41:48.953551Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Review</th>\n",
       "      <th>Original Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Les Choristes</td>\n",
       "      <td>2004</td>\n",
       "      <td>This film tells the story of a music teacher w...</td>\n",
       "      <td>\"The Choristes are a beautiful film that will ...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Blade Runner 2049</td>\n",
       "      <td>2017</td>\n",
       "      <td>Officer K (Ryan Gosling), a new blade runner f...</td>\n",
       "      <td>\"Boring and too long. Nothing like the origina...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Les Visiteurs en Amérique</td>\n",
       "      <td>2000</td>\n",
       "      <td>In this continuation of the French comedy The ...</td>\n",
       "      <td>\"The film is a total wast of time. The jokes a...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>La Tour Montparnasse Infernale</td>\n",
       "      <td>2001</td>\n",
       "      <td>Two incompetent office workers found themselfs...</td>\n",
       "      <td>\"I can't believe I've been time watching this ...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>Don Vito Corleone (Marlon Brando) is the head ...</td>\n",
       "      <td>\"The Godfather is a classic movie that stands ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inception</td>\n",
       "      <td>2010</td>\n",
       "      <td>Dom Cobb (Leonardo DiCaprio) is a skilled thie...</td>\n",
       "      <td>\"Inception is a mind-bending and visually stun...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Amores perros</td>\n",
       "      <td>2000</td>\n",
       "      <td>Three stories intertwine in this Mexican film:...</td>\n",
       "      <td>\"Amores dogs is an intense and moving film tha...</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Babylon A.D.</td>\n",
       "      <td>2008</td>\n",
       "      <td>In the distant future, a mercenary has to esco...</td>\n",
       "      <td>\"This film is a complete mess. The characters ...</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>Andy Dufresne (Tim Robbins), a successful bank...</td>\n",
       "      <td>\"The Shawshank Redemption is an inspiring tale...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Island</td>\n",
       "      <td>2005</td>\n",
       "      <td>In a future where people are cloned for organ ...</td>\n",
       "      <td>\"The Island is a bland and forgettable sci-fi ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title  Year  \\\n",
       "13                   Les Choristes  2004   \n",
       "5                Blade Runner 2049  2017   \n",
       "18       Les Visiteurs en Amérique  2000   \n",
       "16  La Tour Montparnasse Infernale  2001   \n",
       "3                   The Godfather   1972   \n",
       "4                        Inception  2010   \n",
       "24                   Amores perros  2000   \n",
       "19                    Babylon A.D.  2008   \n",
       "0        The Shawshank Redemption   1994   \n",
       "9                       The Island  2005   \n",
       "\n",
       "                                             Synopsis  \\\n",
       "13  This film tells the story of a music teacher w...   \n",
       "5   Officer K (Ryan Gosling), a new blade runner f...   \n",
       "18  In this continuation of the French comedy The ...   \n",
       "16  Two incompetent office workers found themselfs...   \n",
       "3   Don Vito Corleone (Marlon Brando) is the head ...   \n",
       "4   Dom Cobb (Leonardo DiCaprio) is a skilled thie...   \n",
       "24  Three stories intertwine in this Mexican film:...   \n",
       "19  In the distant future, a mercenary has to esco...   \n",
       "0   Andy Dufresne (Tim Robbins), a successful bank...   \n",
       "9   In a future where people are cloned for organ ...   \n",
       "\n",
       "                                               Review Original Language  \n",
       "13  \"The Choristes are a beautiful film that will ...                fr  \n",
       "5   \"Boring and too long. Nothing like the origina...                en  \n",
       "18  \"The film is a total wast of time. The jokes a...                fr  \n",
       "16  \"I can't believe I've been time watching this ...                fr  \n",
       "3   \"The Godfather is a classic movie that stands ...                en  \n",
       "4   \"Inception is a mind-bending and visually stun...                en  \n",
       "24  \"Amores dogs is an intense and moving film tha...                sp  \n",
       "19  \"This film is a complete mess. The characters ...                fr  \n",
       "0   \"The Shawshank Redemption is an inspiring tale...                en  \n",
       "9   \"The Island is a bland and forgettable sci-fi ...                en  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "Use HuggingFace pretrained model for sentiment analysis of the reviews. Store the sentiment result **Positive** or **Negative** in a new column titled **Sentiment** in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:41:59.094929Z",
     "start_time": "2024-10-28T08:41:58.673298Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\"\"\"\n",
    "Device selection for optimal hardware acceleration across different platforms.\n",
    "\n",
    "Process:\n",
    "   - Prioritizes MPS (Metal Performance Shaders) for Apple Silicon Macs\n",
    "   - Falls back to CUDA for NVIDIA GPU acceleration on other systems\n",
    "   - Defaults to CPU if no GPU acceleration is available\n",
    "   \n",
    "Returns:\n",
    "   str: Device identifier (\"mps\", \"cuda\", or \"cpu\") for model computation\n",
    "\"\"\"\n",
    "device = (\n",
    "   \"mps\" if torch.backends.mps.is_available()\n",
    "   else \"cuda\" if torch.cuda.is_available()\n",
    "   else \"cpu\"\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Initializes pre-trained sentiment analysis pipeline with hardware acceleration.\n",
    "\n",
    "Components:\n",
    "   model_name: DistilBERT model fine-tuned on Stanford Sentiment Treebank (SST-2)\n",
    "              Optimized for binary sentiment classification (positive/negative)\n",
    "   sentiment_classifier: HuggingFace pipeline configured for sentiment analysis\n",
    "                        Automatically handles tokenization, inference, and output formatting\n",
    "   device: Hardware accelerator assignment for faster inference\n",
    "   \n",
    "Returns:\n",
    "   transformers.Pipeline: Ready-to-use sentiment analysis classifier\n",
    "\"\"\"\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "sentiment_classifier = pipeline(\n",
    "   \"sentiment-analysis\", \n",
    "   model=model_name,\n",
    "   device=device \n",
    ")\n",
    "\n",
    "def analyze_sentiment(text, classifier):\n",
    "   \"\"\"\n",
    "   Performs binary sentiment classification on input text with confidence thresholding.\n",
    "   \n",
    "   Parameters:\n",
    "       text (str): Input text to analyze for sentiment\n",
    "       classifier: Pre-configured HuggingFace sentiment analysis pipeline\n",
    "       \n",
    "   Process:\n",
    "       1. Passes text through the sentiment classifier pipeline\n",
    "       2. Extracts the top prediction result (label and confidence score)\n",
    "       3. Applies dual criteria: positive label AND confidence > 0.5 threshold\n",
    "       4. Returns simplified binary classification\n",
    "       \n",
    "   Returns:\n",
    "       str: \"Positive\" if prediction is POSITIVE with score > 0.5, otherwise \"Negative\"\n",
    "            Conservative approach ensures high-confidence positive classifications\n",
    "            \n",
    "   Example:\n",
    "       >>> analyze_sentiment(\"This movie is amazing!\", sentiment_classifier)\n",
    "       \"Positive\"\n",
    "       >>> analyze_sentiment(\"Not sure about this film\", sentiment_classifier)\n",
    "       \"Negative\"\n",
    "   \"\"\"\n",
    "   result = classifier(text)[0]\n",
    "   # Return \"Positive\" if POSITIVE label and score > 0.5, else \"Negative\"\n",
    "   return \"Positive\" if result['label'] == 'POSITIVE' and result['score'] > 0.5 else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:42:12.991789Z",
     "start_time": "2024-10-28T08:42:11.372980Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\"\"\"\n",
    "Creates output directory for storing processed results with error handling.\n",
    "\n",
    "Process:\n",
    "   - Creates \"result\" directory in current working path\n",
    "   - exist_ok=True prevents errors if directory already exists\n",
    "   - Ensures output location is available before file operations\n",
    "   \n",
    "Side Effects:\n",
    "   Creates filesystem directory structure for data export\n",
    "\"\"\"\n",
    "os.makedirs(\"result\", exist_ok=True)\n",
    "\n",
    "def clean_text(text):\n",
    "   \"\"\"\n",
    "   Sanitizes and validates text data for sentiment analysis processing.\n",
    "   \n",
    "   Parameters:\n",
    "       text: Raw text input that may contain NaN values, quotes, or invalid types\n",
    "       \n",
    "   Process:\n",
    "       1. Checks for pandas NaN values, string 'nan', or non-string types\n",
    "       2. Returns empty string for invalid/missing data\n",
    "       3. Strips surrounding quote marks from valid text strings\n",
    "       \n",
    "   Returns:\n",
    "       str: Clean text ready for analysis, or empty string if invalid input\n",
    "       \n",
    "   Purpose:\n",
    "       Prevents sentiment analysis errors from malformed or missing text data\n",
    "   \"\"\"\n",
    "   if pd.isna(text) or text == 'nan' or not isinstance(text, str):\n",
    "       return \"\"\n",
    "   return text.strip('\"')  # Remove quote marks that appear in reviews\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Data preprocessing pipeline for sentiment analysis preparation.\n",
    "\n",
    "Process:\n",
    "   1. Applies text cleaning function to all review entries\n",
    "   2. Filters out rows with empty reviews to ensure valid analysis input\n",
    "   3. Generates sentiment predictions for all remaining review text\n",
    "   4. Restructures DataFrame with essential columns for final output\n",
    "   \n",
    "Side Effects:\n",
    "   - Modifies original DataFrame by cleaning and filtering data\n",
    "   - Adds new 'Review Sentiment' column with classification results\n",
    "\"\"\"\n",
    "df['Review'] = df['Review'].apply(clean_text)\n",
    "df = df[df['Review'] != \"\"]\n",
    "\n",
    "df['Review Sentiment'] = df['Review'].apply(lambda x: analyze_sentiment(x, sentiment_classifier))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Column selection and DataFrame restructuring for final output specification.\n",
    "\n",
    "Purpose:\n",
    "   - Removes unnecessary columns that accumulated during data processing pipeline\n",
    "   - Reorders columns in logical sequence for analysis and presentation\n",
    "   - Creates clean, focused dataset containing only essential information\n",
    "   \n",
    "Why this is needed:\n",
    "   Throughout the processing pipeline, the original DataFrame likely contained many columns\n",
    "   such as intermediate processing flags, temporary variables, or unused metadata.\n",
    "   This line explicitly selects and reorders only the 6 columns needed for final analysis.\n",
    "   \n",
    "Column rationale:\n",
    "   - 'Title': Movie identification\n",
    "   - 'Year': Temporal context for analysis\n",
    "   - 'Synopsis': Plot summary content\n",
    "   - 'Review': User review text (cleaned and translated)\n",
    "   - 'Review Sentiment': Generated sentiment classification\n",
    "   - 'Original Language': Language tracking for quality control\n",
    "   \n",
    "Benefits:\n",
    "   - Reduces file size by eliminating unused columns\n",
    "   - Ensures consistent column order across different data runs\n",
    "   - Prevents accidental inclusion of intermediate processing artifacts\n",
    "   - Creates standardized output format for downstream applications\n",
    "   \n",
    "Returns:\n",
    "   DataFrame: Restructured with exactly 6 columns in specified order\n",
    "\"\"\"\n",
    "df = df[['Title', 'Year', 'Synopsis', 'Review', 'Review Sentiment', 'Original Language']]\n",
    "\n",
    "\"\"\"\n",
    "Dataset sampling and quality validation for final output.\n",
    "\n",
    "Process:\n",
    "   1. Limits dataset to first 30 rows for manageable sample size\n",
    "   2. Validates expected row count and warns if data is insufficient\n",
    "   3. Checks for presence of all required columns\n",
    "   4. Exports processed data to CSV format for further analysis\n",
    "   \n",
    "Quality Checks:\n",
    "   - Row count validation ensures adequate sample size\n",
    "   - Column validation prevents downstream processing errors\n",
    "   \n",
    "Output:\n",
    "   CSV file saved to \"result/reviews_with_sentiment.csv\" containing processed data\n",
    "\"\"\"\n",
    "df = df.head(30)\n",
    "\n",
    "if len(df) != 30:\n",
    "   print(f\"Warning: Expected 30 rows but got {len(df)} rows\")\n",
    "\n",
    "required_columns = ['Title', 'Year', 'Synopsis', 'Review', 'Review Sentiment', 'Original Language']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "   print(f\"Warning: Missing required columns: {missing_columns}\")\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"result/reviews_with_sentiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:42:17.531768Z",
     "start_time": "2024-10-28T08:42:17.524434Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review Sentiment</th>\n",
       "      <th>Original Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>La Tour Montparnasse Infernale</td>\n",
       "      <td>2001</td>\n",
       "      <td>Two incompetent office workers found themselfs...</td>\n",
       "      <td>I can't believe I've been time watching this n...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Solo: A Star Wars Story</td>\n",
       "      <td>2018</td>\n",
       "      <td>A young Han Solo (Alden Ehrenreich) joins a gr...</td>\n",
       "      <td>Dull and pointless, with none of the magic of ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>El Incidente</td>\n",
       "      <td>2014</td>\n",
       "      <td>In this Mexican horror film, a group of people...</td>\n",
       "      <td>The Incident is a bore and fairless film that ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Y tu mamá también</td>\n",
       "      <td>2001</td>\n",
       "      <td>Two teenage friends (Gael García Bernal and Di...</td>\n",
       "      <td>And your mom is also a movie that stays with y...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>El Laberinto del Fauno</td>\n",
       "      <td>2006</td>\n",
       "      <td>During the Spanish postwar period, Ofelia (Iva...</td>\n",
       "      <td>The Labyrinth of Fauno is a fascinating and em...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Amélie</td>\n",
       "      <td>2001</td>\n",
       "      <td>This romantic comedy tells the story of Amélie...</td>\n",
       "      <td>Amélie is an absolute charm film that will mak...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Les Choristes</td>\n",
       "      <td>2004</td>\n",
       "      <td>This film tells the story of a music teacher w...</td>\n",
       "      <td>The Choristes are a beautiful film that will m...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Le Dîner de Cons</td>\n",
       "      <td>1998</td>\n",
       "      <td>The film follows the story of a group of rich ...</td>\n",
       "      <td>I didn't like this movie at all. The concept o...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Scott Pilgrim vs. the World</td>\n",
       "      <td>2010</td>\n",
       "      <td>Scott Pilgrim (Michael Cera) must defeat his n...</td>\n",
       "      <td>It was difficult to sit through the whole thin...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Nice Guys</td>\n",
       "      <td>2016</td>\n",
       "      <td>In 1970s Los Angeles, a private eye (Ryan Gosl...</td>\n",
       "      <td>The Nice Guys tries too hard to be funny, and ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Title  Year  \\\n",
       "16  La Tour Montparnasse Infernale  2001   \n",
       "8          Solo: A Star Wars Story  2018   \n",
       "29                    El Incidente  2014   \n",
       "22               Y tu mamá también  2001   \n",
       "23          El Laberinto del Fauno  2006   \n",
       "12                          Amélie  2001   \n",
       "13                   Les Choristes  2004   \n",
       "15                Le Dîner de Cons  1998   \n",
       "6      Scott Pilgrim vs. the World  2010   \n",
       "7                    The Nice Guys  2016   \n",
       "\n",
       "                                             Synopsis  \\\n",
       "16  Two incompetent office workers found themselfs...   \n",
       "8   A young Han Solo (Alden Ehrenreich) joins a gr...   \n",
       "29  In this Mexican horror film, a group of people...   \n",
       "22  Two teenage friends (Gael García Bernal and Di...   \n",
       "23  During the Spanish postwar period, Ofelia (Iva...   \n",
       "12  This romantic comedy tells the story of Amélie...   \n",
       "13  This film tells the story of a music teacher w...   \n",
       "15  The film follows the story of a group of rich ...   \n",
       "6   Scott Pilgrim (Michael Cera) must defeat his n...   \n",
       "7   In 1970s Los Angeles, a private eye (Ryan Gosl...   \n",
       "\n",
       "                                               Review Review Sentiment  \\\n",
       "16  I can't believe I've been time watching this n...         Negative   \n",
       "8   Dull and pointless, with none of the magic of ...         Negative   \n",
       "29  The Incident is a bore and fairless film that ...         Negative   \n",
       "22  And your mom is also a movie that stays with y...         Positive   \n",
       "23  The Labyrinth of Fauno is a fascinating and em...         Positive   \n",
       "12  Amélie is an absolute charm film that will mak...         Positive   \n",
       "13  The Choristes are a beautiful film that will m...         Positive   \n",
       "15  I didn't like this movie at all. The concept o...         Negative   \n",
       "6   It was difficult to sit through the whole thin...         Negative   \n",
       "7   The Nice Guys tries too hard to be funny, and ...         Negative   \n",
       "\n",
       "   Original Language  \n",
       "16                fr  \n",
       "8                 en  \n",
       "29                sp  \n",
       "22                sp  \n",
       "23                sp  \n",
       "12                fr  \n",
       "13                fr  \n",
       "15                fr  \n",
       "6                 en  \n",
       "7                 en  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
